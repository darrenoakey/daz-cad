"""Integration tests for LLM functionality.

These tests verify that the LLM integration works correctly and that 
the correct dazllm API methods are being called.
"""

import unittest

try:
    from .llm_client import get_llm, is_llm_available
    from .llm_git_utils import generate_git_commit_message
    from .llm_code_improvement import improve_code_with_llm
except ImportError:
    from llm_client import get_llm, is_llm_available
    from llm_git_utils import generate_git_commit_message
    from llm_code_improvement import improve_code_with_llm


class TestLlmIntegration(unittest.TestCase):
    """Integration tests for LLM functionality."""

    def test_llm_client_has_correct_methods(self):
        """Test that LLM client has the correct dazllm API methods."""
        llm = get_llm()
        if llm is not None:
            # Check that the LLM has the correct method names from dazllm API
            self.assertTrue(hasattr(llm, 'chat'), 
                          "LLM should have 'chat' method from dazllm API")
            
            # Make sure it doesn't have the incorrect 'invoke' method
            self.assertFalse(hasattr(llm, 'invoke'), 
                           "LLM should NOT have 'invoke' method - use 'chat' instead")

    def test_llm_chat_method_works(self):
        """Test that LLM chat method works correctly."""
        llm = get_llm()
        if llm is not None:
            try:
                # Test the chat method with a simple prompt
                response = llm.chat("Say 'test' in one word")
                
                # Response should be a string or have a content attribute
                if hasattr(response, 'content'):
                    result = response.content
                else:
                    result = str(response)
                
                self.assertIsInstance(result, str)
                self.assertGreater(len(result.strip()), 0)
                
            except Exception as e:
                # If there's an error, it shouldn't be about missing 'chat' method
                error_msg = str(e).lower()
                self.assertNotIn("has no attribute 'chat'", error_msg,
                               "LLM should have 'chat' method")
                # Re-raise the exception if it's something else
                if "'chat'" in error_msg:
                    raise

    def test_git_commit_generation_uses_correct_api(self):
        """Test that git commit generation uses correct LLM API."""
        # This should not raise an AttributeError about 'invoke'
        try:
            result = generate_git_commit_message("Test action", "test code")
            self.assertIsInstance(result, str)
            self.assertGreater(len(result), 0)
        except AttributeError as e:
            error_msg = str(e)
            self.assertNotIn("'invoke'", error_msg,
                           "Should use 'chat' method, not 'invoke'")
            # Re-raise if it's a different AttributeError
            raise

    def test_code_improvement_uses_correct_api(self):
        """Test that code improvement uses correct LLM API."""
        def simple_runner(code):
            return {"success": True, "objects": []}
        
        # This should not raise an AttributeError about 'invoke'
        try:
            result = improve_code_with_llm(
                "make it red",
                "box = cq.Workplane().box(1,1,1)",
                simple_runner
            )
            self.assertIsInstance(result, dict)
            self.assertIn("success", result)
        except AttributeError as e:
            error_msg = str(e)
            self.assertNotIn("'invoke'", error_msg,
                           "Should use 'chat' method, not 'invoke'")
            # Re-raise if it's a different AttributeError
            raise

    def test_dazllm_api_methods_available(self):
        """Test that dazllm API methods are correctly available."""
        if is_llm_available():
            try:
                # Try importing dazllm to check available methods
                import dazllm  # pylint: disable=import-outside-toplevel
                
                # Check that Llm class exists and has chat method
                if hasattr(dazllm, 'Llm'):
                    llm_class = dazllm.Llm
                    # Create a test instance to check methods
                    test_llm = llm_class("test:model")
                    self.assertTrue(hasattr(test_llm, 'chat'),
                                  "dazllm.Llm should have 'chat' method")
                
            except ImportError:
                # dazllm not available, skip this test
                self.skipTest("dazllm not available")
            except Exception:
                # Other errors are OK for this test
                pass

    def test_real_llm_chat_call(self):
        """Test making a real LLM chat call if available."""
        if is_llm_available():
            llm = get_llm()
            try:
                # Make a real call to test the API
                response = llm.chat("What is 2+2? Answer with just the number.")
                
                # Verify we get a response
                if hasattr(response, 'content'):
                    result = response.content.strip()
                else:
                    result = str(response).strip()
                
                self.assertIsInstance(result, str)
                self.assertGreater(len(result), 0)
                
            except Exception as e:
                # Check that the error is not about missing 'chat' method
                error_msg = str(e).lower()
                self.assertNotIn("has no attribute 'chat'", error_msg,
                               "LLM should have 'chat' method from dazllm")
                
                # For other errors, just log them but don't fail the test
                print(f"LLM call failed (this may be expected): {e}")
